{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e208b9-dfd3-41ba-9f37-5de6028caa64",
   "metadata": {},
   "source": [
    "There are more advanced SQL features, mostly focused on using BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c832bd2-794c-4d7c-b654-669f0327d2c2",
   "metadata": {},
   "source": [
    "## 1. JOINs and UNIONs\n",
    "\n",
    "### JOINs\n",
    "We can use an INNER JOIN to pull rows from both tables where the value in the Pet_ID column in the owners table has a match in the ID column of the pets table.\n",
    "\n",
    "Note that with a UNION, the data types of both columns must be the same, but the column names can be different. (So, for instance, we cannot take the UNION of the Age column from the owners table and the Pet_Name column from the pets table.)\n",
    "\n",
    "We use UNION ALL to include duplicate values - you'll notice that 9 appears in both the owners table and the pets table, and shows up twice in the concatenated results. If you'd like to drop duplicate values, you need only change UNION ALL in the query to UNION DISTINCT.\n",
    "\n",
    "\n",
    "### UNIONs\n",
    "JOINs horizontally combine results from different tables. If you instead would like to vertically concatenate columns, you can do so with a UNION. The example query below combines the Age columns from both tables.\n",
    "\n",
    "Note that with a UNION, the data types of both columns must be the same, but the column names can be different. (So, for instance, we cannot take the UNION of the Age column from the owners table and the Pet_Name column from the pets table.)\n",
    "\n",
    "We use UNION ALL to include duplicate values - you'll notice that 9 appears in both the owners table and the pets table, and shows up twice in the concatenated results. If you'd like to drop duplicate values, you need only change UNION ALL in the query to UNION DISTINCT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9cc72a-04f1-401b-bc9a-b977a7f25f76",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be43edc-fcb6-4fcd-bb46-b9806b64ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select all stories posted on January 1, 2012, with number of comments\n",
    "join_query = \"\"\"\n",
    "             WITH c AS\n",
    "             (\n",
    "             SELECT parent, COUNT(*) as num_comments\n",
    "             FROM `bigquery-public-data.hacker_news.comments` \n",
    "             GROUP BY parent\n",
    "             )\n",
    "             SELECT s.id as story_id, s.by, s.title, c.num_comments\n",
    "             FROM `bigquery-public-data.hacker_news.stories` AS s\n",
    "             LEFT JOIN c\n",
    "             ON s.id = c.parent\n",
    "             WHERE EXTRACT(DATE FROM s.time_ts) = '2012-01-01'\n",
    "             ORDER BY c.num_comments DESC\n",
    "             \"\"\"\n",
    "\n",
    "# Run the query, and return a pandas DataFrame\n",
    "join_result = client.query(join_query).result().to_dataframe()\n",
    "join_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d04ad-57aa-4157-b47c-35262caeceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select all users who posted stories or comments on January 1, 2014\n",
    "union_query = \"\"\"\n",
    "              SELECT c.by\n",
    "              FROM `bigquery-public-data.hacker_news.comments` AS c\n",
    "              WHERE EXTRACT(DATE FROM c.time_ts) = '2014-01-01'\n",
    "              UNION DISTINCT\n",
    "              SELECT s.by\n",
    "              FROM `bigquery-public-data.hacker_news.stories` AS s\n",
    "              WHERE EXTRACT(DATE FROM s.time_ts) = '2014-01-01'\n",
    "              \"\"\"\n",
    "\n",
    "# Run the query, and return a pandas DataFrame\n",
    "union_result = client.query(union_query).result().to_dataframe()\n",
    "union_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b1620-866a-4396-b1e9-69c40361e294",
   "metadata": {},
   "source": [
    "### 1. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d4ad9-afc6-4c64-a461-d8b8604ea340",
   "metadata": {},
   "source": [
    "Here, you'll use different types of SQL **JOINs** to answer questions about the [Stack Overflow](https://www.kaggle.com/stackoverflow/stackoverflow) dataset.\n",
    "\n",
    "Before you get started, run the following cell to set everything up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66561ac2-652b-4817-8902-2d3ae796affe",
   "metadata": {},
   "source": [
    "The code cell below fetches the `posts_questions` table from the `stackoverflow` dataset.  We also preview the first five rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7397b6b-b1ff-4c31-a2cb-ca0a2fa5b06f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bigquery\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a \"Client\" object\u001b[39;00m\n\u001b[0;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"stackoverflow\" dataset\n",
    "dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"posts_questions\" table\n",
    "table_ref = dataset_ref.table(\"posts_questions\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "972a1aba-159e-4fde-b35e-54c3740a54da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_ref' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Construct a reference to the \"posts_answers\" table\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m table_ref \u001b[38;5;241m=\u001b[39m dataset_ref\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposts_answers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# API request - fetch the table\u001b[39;00m\n\u001b[0;32m      5\u001b[0m table \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_table(table_ref)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_ref' is not defined"
     ]
    }
   ],
   "source": [
    "# Construct a reference to the \"posts_answers\" table\n",
    "table_ref = dataset_ref.table(\"posts_answers\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219cecf-b4fd-4e86-a484-7b4cf2130979",
   "metadata": {},
   "source": [
    "1) How long does it take for questions to receive answers?\n",
    "\n",
    "You're interested in exploring the data to have a better understanding of how long it generally takes for questions to receive answers. Armed with this knowledge, you plan to use this information to better design the order in which questions are presented to Stack Overflow users.\n",
    "\n",
    "With this goal in mind, you write the query below, which focuses on questions asked in January 2018. It returns a table with two columns:\n",
    "\n",
    "    q_id - the ID of the question\n",
    "\n",
    "    time_to_answer - how long it took (in seconds) for the question to receive an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b46f6cf5-bf96-4da4-9dde-918888b8c84d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m first_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m              SELECT q.id AS q_id,\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m                  MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) as time_to_answer\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m              ORDER BY time_to_answer\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m              \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m first_result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(first_query)\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mto_dataframe()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of answered questions: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \\\n\u001b[0;32m     14\u001b[0m       (\u001b[38;5;28msum\u001b[39m(first_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_to_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(first_result) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of questions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(first_result))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "correct_query = \"\"\"\n",
    "              SELECT q.id AS q_id,\n",
    "                  MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) as time_to_answer\n",
    "              FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                  Left Join `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "              ON q.id = a.parent_id\n",
    "              WHERE q.creation_date >= '2018-01-01' and q.creation_date < '2018-02-01'\n",
    "              GROUP BY q_id\n",
    "              ORDER BY time_to_answer\n",
    "              \"\"\"\n",
    "\n",
    "# Run the query, and return a pandas DataFrame\n",
    "correct_result = client.query(correct_query).result().to_dataframe()\n",
    "print(\"Percentage of answered questions: %s%%\" % \\\n",
    "      (sum(correct_result[\"time_to_answer\"].notnull()) / len(correct_result) * 100))\n",
    "print(\"Number of questions:\", len(correct_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa08ecd-af4e-4ff4-824f-0274b2b64877",
   "metadata": {},
   "source": [
    "2) Initial questions and answers, Part 1\n",
    "\n",
    "You're interested in understanding the initial experiences that users typically have with the Stack Overflow website. Is it more common for users to first ask questions or provide answers? After signing up, how long does it take for users to first interact with the website? To explore this further, you draft the (partial) query in the code cell below.\n",
    "\n",
    "The query returns a table with three columns:\n",
    "\n",
    "owner_user_id - the user ID\n",
    "q_creation_date - the first time the user asked a question\n",
    "a_creation_date - the first time the user contributed an answer\n",
    "You want to keep track of users who have asked questions, but have yet to provide answers. And, your table should also include users who have answered questions, but have yet to pose their own questions.\n",
    "\n",
    "With this in mind, please fill in the appropriate JOIN (i.e., INNER, LEFT, RIGHT, or FULL) to return the correct information.\n",
    "\n",
    "Note: You need only fill in the appropriate JOIN. All other parts of the query should be left as-is. (You also don't need to write any additional code to run the query, since the check() method will take care of this for you.)\n",
    "\n",
    "To avoid returning too much data, we'll restrict our attention to questions and answers posed in January 2019. We'll amend the timeframe in Part 2 of this question to be more realistic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fadd230a-5a9c-4103-b4c2-f285df2938ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "q_and_a_query = \"\"\"\n",
    "                SELECT q.owner_user_id AS owner_user_id,\n",
    "                    MIN(q.creation_date) AS q_creation_date,\n",
    "                    MIN(a.creation_date) AS a_creation_date\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                    inner join `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                ON q.owner_user_id = a.owner_user_id \n",
    "                WHERE q.creation_date >= '2019-01-01' AND q.creation_date < '2019-02-01' \n",
    "                    AND a.creation_date >= '2019-01-01' AND a.creation_date < '2019-02-01'\n",
    "                GROUP BY owner_user_id\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e986e5-9e67-4a5c-af46-6e8e2e0441bc",
   "metadata": {},
   "source": [
    "3) Initial questions and answers, Part 2\n",
    "\n",
    "Now you'll address a more realistic (and complex!) scenario. Write a query that returns the following columns:\n",
    "\n",
    "    id - the IDs of all users who created Stack Overflow accounts in January 2019 (January 1, 2019, to January 31, 2019, inclusive)\n",
    "    q_creation_date - the first time the user posted a question on the site; if the user has never posted a question, the value should be null\n",
    "    a_creation_date - the first time the user posted a question on the site; if the user has never posted a question, the value should be null\n",
    "\n",
    "Note that questions and answers posted after January 31, 2019, should still be included in the results. And, all users who joined the site in January 2019 should be included (even if they have never posted a question or provided an answer).\n",
    "\n",
    "The query from the previous question should be a nice starting point to answering this question! You'll need to use the posts_answers and posts_questions tables. You'll also need to use the users table from the Stack Overflow dataset. The relevant columns from the users table are id (the ID of each user) and creation_date (when the user joined the Stack Overflow site, in DATETIME format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89e0b08b-a582-47c5-ac61-da17a0283b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "three_tables_query = \"\"\"\n",
    "                SELECT u.id AS id,\n",
    "                MIN(q.creation_date) AS q_creation_date,\n",
    "                MIN(a.creation_date) AS a_creation_date\n",
    "                FROM `bigquery-public-data.stackoverflow.users` AS u\n",
    "                    left join `bigquery-public-data.stackoverflow.posts_questions` AS q ON u.id = q.owner_user_id\n",
    "                    left join `bigquery-public-data.stackoverflow.posts_answers` AS a ON a.owner_user_id = u.id\n",
    "                WHERE u.creation_date >= '2019-01-01' AND u.creation_date < '2019-02-01' \n",
    "                GROUP BY id\n",
    "                \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77335291-c897-4dde-94e2-d8f44e8b8bd7",
   "metadata": {},
   "source": [
    "4) How many distinct users posted on January 1, 2019?¶\n",
    "\n",
    "In the code cell below, write a query that returns a table with a single column:\n",
    "\n",
    "    owner_user_id - the IDs of all users who posted at least one question or answer on January 1, 2019. Each user ID should appear at most once.\n",
    "\n",
    "In the posts_questions (and posts_answers) tables, you can get the ID of the original poster from the owner_user_id column. Likewise, the date of the original posting can be found in the creation_date column.\n",
    "\n",
    "In order for your answer to be marked correct, your query must use a UNION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81c13603-3f8d-4c1f-884e-18f47177dc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "all_users_query = \"\"\"\n",
    "                SELECT q.owner_user_id\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                WHERE EXTRACT(DATE FROM q.creation_date) = '2019-01-01'\n",
    "                UNION DISTINCT\n",
    "                SELECT a.owner_user_id\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                WHERE EXTRACT(DATE FROM a.creation_date) = '2019-01-01'\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9f884-3727-41d1-a43f-3d50644e1330",
   "metadata": {},
   "source": [
    "## 2. Analytic Functions\n",
    "\n",
    "All analytic functions have an OVER clause, which defines the sets of rows used in each calculation. The OVER clause has three (optional) parts:\n",
    "\n",
    "    - The PARTITION BY clause divides the rows of the table into different groups. In the query above, we divide by id so that the calculations are separated by runner.\n",
    "    - The ORDER BY clause defines an ordering within each partition. In the sample query, ordering by the date column ensures that earlier training sessions appear first.\n",
    "    - The final clause (ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) is known as a window frame clause. It identifies the set of rows used in each calculation. We can refer to this group of rows as a window. (Actually, analytic functions are sometimes referred to as analytic window functions or simply window functions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4a3d91e-9dd3-4f3c-b98d-03f706e31dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *,\n",
    "            AVG(time)OVER(\n",
    "                          PARTITION BY id\n",
    "                          ORDER BY date\n",
    "                          ROWS BETWEEN 1 PRECEDING AND CURRENT ROW\n",
    "                          ) as avg_time\n",
    "        FROM `bigquery-public-data.runners.train_time`\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e2fe7-12ce-49a3-9432-b7645f097241",
   "metadata": {},
   "source": [
    "There are many ways to write window frame clauses:\n",
    "\n",
    "    ROWS BETWEEN 1 PRECEDING AND CURRENT ROW - the previous row and the current row.\n",
    "    ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING - the 3 previous rows, the current row, and the following row.\n",
    "    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING - all rows in the partition.\n",
    "\n",
    "Of course, this is not an exhaustive list, and you can imagine that there are many more options! In the code below, you'll see some of these clauses in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2950dbbf-6208-43a3-b3a0-44564d5c6692",
   "metadata": {},
   "source": [
    "### Three types of analytic functions\n",
    "The example above uses only one of many analytic functions. BigQuery supports a wide variety of analytic functions, and we'll explore a few here. For a complete listing, you can take a look at the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea48142-ddd0-430f-b41d-ad0fcbd0c238",
   "metadata": {},
   "source": [
    "1) Analytic aggregate functions\n",
    "As you might recall, AVG() (from the example above) is an aggregate function. The OVER clause is what ensures that it's treated as an analytic (aggregate) function. Aggregate functions take all of the values within the window as input and return a single value.\n",
    "\n",
    "    - MIN() (or MAX()) - Returns the minimum (or maximum) of input values\n",
    "    \n",
    "    - AVG() (or SUM()) - Returns the average (or sum) of input values\n",
    "    \n",
    "    - COUNT() - Returns the number of rows in the input\n",
    "\n",
    "2) Analytic navigation functions\n",
    "Navigation functions assign a value based on the value in a (usually) different row than the current row.\n",
    "\n",
    "    - FIRST_VALUE() (or LAST_VALUE()) - Returns the first (or last) value in the input\n",
    "    \n",
    "    - LEAD() (and LAG()) - Returns the value on a subsequent (or preceding) row\n",
    "\n",
    "3) Analytic numbering functions\n",
    "Numbering functions assign integer values to each row based on the ordering.\n",
    "\n",
    "    - ROW_NUMBER() - Returns the order in which rows appear in the input (starting with 1)\n",
    "\n",
    "    - RANK() - All rows with the same value in the ordering column receive the same rank value, where the next row receives a rank value which increments by the number of rows with the previous rank value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709e421-d3c4-4cb2-a519-655f9a07c954",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3ccd8dd-1155-4b1e-af7d-25aca6cccc47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 21\u001b[0m\n\u001b[0;32m      2\u001b[0m num_trips_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m                  WITH trips_by_day AS\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m                  (\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m                      FROM trips_by_day\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m                  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Run the query, and return a pandas DataFrame\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m num_trips_result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(num_trips_query)\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mto_dataframe()\n\u001b[0;32m     22\u001b[0m num_trips_result\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Query to count the (cumulative) number of trips per day\n",
    "num_trips_query = \"\"\"\n",
    "                  WITH trips_by_day AS\n",
    "                  (\n",
    "                  SELECT DATE(start_date) AS trip_date,\n",
    "                      COUNT(*) as num_trips\n",
    "                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "                  WHERE EXTRACT(YEAR FROM start_date) = 2015\n",
    "                  GROUP BY trip_date\n",
    "                  )\n",
    "                  SELECT *,\n",
    "                      SUM(num_trips) \n",
    "                          OVER (\n",
    "                               ORDER BY trip_date\n",
    "                               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "                               ) AS cumulative_trips\n",
    "                      FROM trips_by_day\n",
    "                  \"\"\"\n",
    "\n",
    "# Run the query, and return a pandas DataFrame\n",
    "num_trips_result = client.query(num_trips_query).result().to_dataframe()\n",
    "num_trips_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea78db9-2250-43a1-9610-b5e9285865ab",
   "metadata": {},
   "source": [
    "The query uses a common table expression (CTE) to first calculate the daily number of trips. Then, we use SUM() as an aggregate function.\n",
    "\n",
    "    - Since there is no PARTITION BY clause, the entire table is treated as a single partition.\n",
    "    - The ORDER BY clause orders the rows by date, where earlier dates appear first.\n",
    "    - By setting the window frame clause to ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW, we ensure that all rows up to and including the current date are used to calculate the (cumulative) sum. (Note: If you read the documentation, you'll see that this is the default behavior, and so the query would return the same result if we left out this window frame clause.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f20329-2c6d-44c5-8f47-45b4e82a83fc",
   "metadata": {},
   "source": [
    "The next query tracks the stations where each bike began (in start_station_id) and ended (in end_station_id) the day on October 25, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34c468d2-94ef-4698-b929-50b0fc783470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 24\u001b[0m\n\u001b[0;32m      2\u001b[0m start_end_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m                  SELECT bike_number,\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m                      TIME(start_date) AS trip_time,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m                  WHERE DATE(start_date) = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015-10-25\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m                  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Run the query, and return a pandas DataFrame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m start_end_result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(start_end_query)\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mto_dataframe()\n\u001b[0;32m     25\u001b[0m start_end_result\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Query to track beginning and ending stations on October 25, 2015, for each bike\n",
    "start_end_query = \"\"\"\n",
    "                  SELECT bike_number,\n",
    "                      TIME(start_date) AS trip_time,\n",
    "                      FIRST_VALUE(start_station_id)\n",
    "                          OVER (\n",
    "                               PARTITION BY bike_number\n",
    "                               ORDER BY start_date\n",
    "                               ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "                               ) AS first_station_id,\n",
    "                      LAST_VALUE(end_station_id)\n",
    "                          OVER (\n",
    "                               PARTITION BY bike_number\n",
    "                               ORDER BY start_date\n",
    "                               ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "                               ) AS last_station_id,\n",
    "                      start_station_id,\n",
    "                      end_station_id\n",
    "                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "                  WHERE DATE(start_date) = '2015-10-25' \n",
    "                  \"\"\"\n",
    "\n",
    "# Run the query, and return a pandas DataFrame\n",
    "start_end_result = client.query(start_end_query).result().to_dataframe()\n",
    "start_end_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e00305-05e0-466f-8ee6-8bf2fb7062da",
   "metadata": {},
   "source": [
    "The query uses both FIRST_VALUE() and LAST_VALUE() as analytic functions.\n",
    "\n",
    "    - The PARTITION BY clause breaks the data into partitions based on the bike_number column. Since this column holds unique identifiers for the bikes, this ensures the calculations are performed separately for each bike.\n",
    "    - The ORDER BY clause puts the rows within each partition in chronological order.\n",
    "    - Since the window frame clause is ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING, for each row, its entire partition is used to perform the calculation. (This ensures the calculated values for rows in the same partition are identical.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03aeef2-491c-45b4-932a-cef3214afcba",
   "metadata": {},
   "source": [
    "### 2. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a511d08-11d3-4806-a7cd-4af72f6bb122",
   "metadata": {},
   "source": [
    "The following code cell fetches the `taxi_trips` table from the `chicago_taxi_trips` dataset. We also preview the first five rows of the table.  You'll use the table to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e00f632-61ed-4793-a292-17aabc114859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bigquery\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a \"Client\" object\u001b[39;00m\n\u001b[0;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"chicago_taxi_trips\" dataset\n",
    "dataset_ref = client.dataset(\"chicago_taxi_trips\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"taxi_trips\" table\n",
    "table_ref = dataset_ref.table(\"taxi_trips\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec454f-65f2-49d8-83c0-4602f93f384a",
   "metadata": {},
   "source": [
    "1) How can you predict the demand for taxis?¶\n",
    "Say you work for a taxi company, and you're interested in predicting the demand for taxis. Towards this goal, you'd like to create a plot that shows a rolling average of the daily number of taxi trips. Amend the (partial) query below to return a DataFrame with two columns:\n",
    "\n",
    "    - trip_date - contains one entry for each date from January 1, 2016, to March 31, 2016.\n",
    "    - avg_num_trips - shows the average number of daily trips, calculated over a window including the value for the current date, along with the values for the preceding 3 days and the following 3 days, as long as the days fit within the three-month time frame. For instance, when calculating the value in this column for January 3, 2016, the window will include the number of trips for the preceding 2 days, the current date, and the following 3 days.\n",
    "\n",
    "This query is partially completed for you, and you need only write the part that calculates the avg_num_trips column. Note that this query uses a common table expression (CTE); if you need to review how to use CTEs, you're encouraged to check out this tutorial in the Intro to SQL course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee60ec33-f4d2-4c7f-b01f-ef8d79e81e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in the blank below\n",
    "avg_num_trips_query = \"\"\"\n",
    "                      WITH trips_by_day AS\n",
    "                      (\n",
    "                      SELECT DATE(trip_start_timestamp) AS trip_date,\n",
    "                          COUNT(*) as num_trips\n",
    "                      FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                      WHERE trip_start_timestamp > '2016-01-01' AND trip_start_timestamp < '2016-04-01'\n",
    "                      GROUP BY trip_date\n",
    "                      ORDER BY trip_date\n",
    "                      )\n",
    "                      SELECT trip_date,\n",
    "                          AVG(num_trips)\n",
    "                          OVER (\n",
    "                               ORDER BY trip_date\n",
    "                               ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING\n",
    "                               ) AS avg_num_trips\n",
    "                      FROM trips_by_day\n",
    "                      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad1e26-6c7d-4957-9649-b948697b3995",
   "metadata": {},
   "source": [
    "2) Can you separate and order trips by community area?¶\n",
    "\n",
    "The query below returns a DataFrame with three columns from the table: pickup_community_area, trip_start_timestamp, and trip_end_timestamp.\n",
    "\n",
    "Amend the query to return an additional column called trip_number which shows the order in which the trips were taken from their respective community areas. So, the first trip of the day originating from community area 1 should receive a value of 1; the second trip of the day from the same area should receive a value of 2. Likewise, the first trip of the day from community area 2 should receive a value of 1, and so on.\n",
    "\n",
    "Note that there are many numbering functions that can be used to solve this problem (depending on how you want to deal with trips that started at the same time from the same community area); to answer this question, please use the RANK() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "082d29b8-7ace-4ca4-bd5c-f6975f789a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Amend the query below\n",
    "trip_number_query = \"\"\"\n",
    "                    SELECT pickup_community_area,\n",
    "                        trip_start_timestamp,\n",
    "                        trip_end_timestamp,\n",
    "                        RANK()\n",
    "                            OVER (\n",
    "                                PARTITION BY pickup_community_area\n",
    "                                ORDER BY trip_start_timestamp\n",
    "                                ) AS trip_number\n",
    "                    FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                    WHERE DATE(trip_start_timestamp) = '2013-10-03'\n",
    "                    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29316c0-8b45-402a-8781-312152b45c31",
   "metadata": {},
   "source": [
    "3) How much time elapses between trips?\n",
    "\n",
    "The (partial) query in the code cell below shows, for each trip in the selected time frame, the corresponding taxi_id, trip_start_timestamp, and trip_end_timestamp.\n",
    "\n",
    "Your task in this exercise is to edit the query to include an additional prev_break column that shows the length of the break (in minutes) that the driver had before each trip started (this corresponds to the time between trip_start_timestamp of the current trip and trip_end_timestamp of the previous trip). Partition the calculation by taxi_id, and order the results within each partition by trip_start_timestamp.\n",
    "\n",
    "Some sample results are shown below, where all rows correspond to the same driver (or taxi_id). Take the time now to make sure that the values in the prev_break column make sense to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df51b89c-1bb8-496f-a991-2b7f40e865be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in the blanks below\n",
    "break_time_query = \"\"\"\n",
    "                   SELECT taxi_id,\n",
    "                       trip_start_timestamp,\n",
    "                       trip_end_timestamp,\n",
    "                       TIMESTAMP_DIFF(\n",
    "                           trip_start_timestamp, \n",
    "                           LAG (trip_end_timestamp, 1) \n",
    "                               OVER (\n",
    "                                    PARTITION BY taxi_id \n",
    "                                    ORDER BY trip_start_timestamp), \n",
    "                           MINUTE) as prev_break\n",
    "                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                   WHERE DATE(trip_start_timestamp) = '2013-10-03' \n",
    "                   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332cbf5-1c70-4e1b-8849-f14220571186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
